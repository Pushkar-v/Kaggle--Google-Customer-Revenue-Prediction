# Kaggle: Google Customer Revenue Prediction

[Kaggle Link](https://www.kaggle.com/c/ga-customer-revenue-prediction)

## Project Definition & Introduction

### Background & Context

Google runs a merchandise where they sell Google branded goods. The store is also known as GStore. The task for the Kaggle competition is to analyze customer dataset from a GStore to predict revenue per customer. This prediction can help managers to Identify potential customers and Market to them and also plan for store inventory management for improving in-store customer experience.

### Problem Statement

The 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies. In the real world, this translates to a lot of potential marketing investment not yielding the inten ded return in revenue.

Given the tools and techniques in data analysis, our task is to generate actionable operational changes and provide insights that can be used to dedicate marketing budgets more effectively not just for GStore, but also for those companies that wish to use data analysis on top of GA data.

### Key Question

Can a predictive model prove useful to GStore for closely estimating revenue generated by visitors over a certain period of time? These estimations can be used for inventory management to balance demand and supply, future planning and also by the marketing team to design promotional strategies to target people at appropriate times.

### Solution Overview

The final solution is a two step approach in which we first use a classification model and a stacked regression model to identify as well as predict customer revenue.
We first predict customer’s tendency to make a purchase in the store. We first want to know what leads to a customer completing a purchase on the store before we try to estimate how much he purchases. 

For this we try to maximize the recall score of the model so that we capture all possible purchases. Next, we use this prediction as an indicator for predicting the revenue for these customers. We filter only the customers who have made a purchase from the first prediction and predict revenue for those customers only. This helps reduce the final error (rmse) and give out a better prediction.

Finally our goal for this prediction is to find important features, which can aid a manager in
finding potential customers who are likely to make a purchase. These customers can be
targeted and also, Store planning can be accordingly done for better customer experience.



## Data Mining

### Data Exploration

We are provided with 2 datasets, train and test with following sizes.
**train.csv - 24 GB**
**test.csv - 7 GB**
The prediction variable is the logarithmic revenue of the store visit, which is required at a customer level. Each row in the data represents a visit by a customer, and there are various attributes captures by google analytics for one visit.

The data fields in the given files with their data understanding are as below:

1. **fullVisitorId**- Unique Customer ID
2. **channelGrouping** - How User visited the store
3. **date** - The date on which the user visited the Store.
4. **device** - Details on how user accessed the website
5. **geoNetwork** - User Geographic details demographics data
6. **sessionId** - Unique ID for the session of the user
7.  **socialEngagementType** - "Socially Engaged" / "Not Socially Engaged".
8. **totals** - These contains various session attributes
9. **trafficSource** - Traffic Source of the section
10. **visitId** - An identifier for this visit
11. **visitNumber** - The session number for this user. If this is the first visit, then this is set to 1.
12. **visitStartTime** - The timestamp for the visit

The train data ranges from 1st August 2016 to 30th April 2018. And the test data is for 5.5 months ranging from 1st May 2019 to 15th October 2019.

Many data fields are also in Json format which first needs to be unpacked and flattened into columns, before analyzing and using the data.



### Data Cleaning

The imported data had following files in JSON format. We use the following function to flatten these files and convert them into required columns.

```python
JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']
for column in JSON_COLUMNS:
    column_as_df = json_normalize(df1[column])
    column_as_df.columns = [f"{column}.{subcolumn}" for subcolumn in
    column_as_df.columns]
    df1 = df1.drop(column, axis=1).merge(column_as_df, right_index=True,
    left_index=True, how = 'left')
```

These expanded fields give multiple columns which have no values in them and are zero. We neglect these columns and go ahead with columns which have further values in them for feature selection.



### Data Transformation

The data contains the fields at a visit level, and required prediction is at a customer level. We group the fields at a customer level to get the required aggregation. We group all numeric features at a customer level for the final dataset creation and encode all categorical variables into one-hot encoding.

For the categorical variables, we do not use all the available categories but only the ones which make sense. We select top 5 categories in each of the fields by frequency and club all other categories as ‘others’ to keep the dimensionality of the dataset small.



### Feature Selection

We select features from the data for analysis. Not all features are useful, and not all features have consistent values. We select the following features as per business understanding. 

We group the features into 4 distinct categories.

1. Web Traffic Data : Organic Search, Channel

2. Session Data : Hits, Visits, PageViews, Time spent on site, clicks

3. User Experience : Session Quality, Exits, Bounces, Hits, Bounces etc.

4. User Demographics : Geography, Time of the Day, Device, Browser etc.



After flattening nested JSON structures of the data, we generate 113 individual features in total. These data fields include channels via which the user came to the store, devices used to access the store, number of hits, page visits, time spent during each customer visit to the store and so on. The comprehensive data introduction can be found under Kaggle competition’s webpage: https://www.kaggle.com/c/ga-customer-revenue-prediction/data .

For evaluating which features to include, we explored values in each data column and made selection based on the predictive power of the features. For example, visitorID is a unique identifier for distinctions among customers, but it does not preserve any predictive power over the revenue a customer will spend. Similarly, the longitude and latitude of the geographic location during the visit is useful for data visualizations, but it does not add additional information for revenue prediction (since the city, the country are also presented in data fields). In addition, we discovered that there are 19 features that have constant values in the train set, so we decided to drop these features as they do not bring useful information and will slow down the modeling process.

After dropping consistent and unrelated features, we narrowed down the number of predictors to. A complete variables that we include in the model can be found in figure 1 in the appendix.



### Data Preparation - Rolling Window

As we needed to predict the revenue of customers in 5.5 months(provided in test data), we took 5.5 months of instances for each customers at different points of time. We were able to get three groups of time period to consider (August’16 - January’17), (February’17 - July’17), (August’17 - January’18). This approach gave us 1,052,414 number of rows, out of which 3,531 were with transactions. It was 0.34% of the total data. This showed us that the data was highly imbalanced and there were very few customers with transactions. To tackle this situation, we took a rolling window of 5.5 months.



| From         | To     |
| ------------ | ------ |
| August 16    | Jan17  |
| September 16 | Feb 17 |
| October16    | Mar 17 |
| November 16  | Apr 17 |
| Dec 16       | May 17 |
| Jan17        | Jun 17 |
| Feb 17       | Jul 17 |
| Mar 17       | Aug 17 |
| Apr 17       | Sep 17 |
| May 17       | Oct 17 |
| Jun 17       | Nov 17 |
| Jul 17       | Dec 17 |
| Aug 17       | Jan 18 |

This gave us 13 sets of datasets. Now we get 4,377,621 rows, out of which 16,409 were with transactions. After increasing no of instances with revenue, the data was too large to handle and run predictive models on to get results. So we under sampled the transactions without revenue. This helped us to get the data at a manageable level without losing any information on the instances with transactions. After under sampling we get 3.7% of customers with transactions.



### Challenges Faced

While using this data set we faced a few challenges. The first and foremost was dealing with the huge amount of data (31 GB). We used Google’s cloud services like Big Query, their high configuration instances and Storage. Secondly, the data was on transaction level, but we needed to provide customer level revenue, so we grouped the data into customer level. We figured that there are very few instances of transactions. For that, we used rolling period of transactions, this increased our instances with transactions. This method gave us a vast amount of data which we could not handle to run predictive algorithms on. We under sampled our non transactional instances.