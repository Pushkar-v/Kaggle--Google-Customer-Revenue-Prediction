# Kaggle: Google Customer Revenue Prediction

[Kaggle Link](https://www.kaggle.com/c/ga-customer-revenue-prediction)

## Project Definition & Introduction

### Background & Context

Google runs a merchandise where they sell Google branded goods. The store is also known as GStore. The task for the Kaggle competition is to analyze customer dataset from a GStore to predict revenue per customer. This prediction can help managers to Identify potential customers and Market to them and also plan for store inventory management for improving in-store customer experience.

### Problem Statement

The 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies. In the real world, this translates to a lot of potential marketing investment not yielding the inten ded return in revenue.

Given the tools and techniques in data analysis, our task is to generate actionable operational changes and provide insights that can be used to dedicate marketing budgets more effectively not just for GStore, but also for those companies that wish to use data analysis on top of GA data.

### Key Question

Can a predictive model prove useful to GStore for closely estimating revenue generated by visitors over a certain period of time? These estimations can be used for inventory management to balance demand and supply, future planning and also by the marketing team to design promotional strategies to target people at appropriate times.

### Solution Overview

The final solution is a two step approach in which we first use a classification model and a stacked regression model to identify as well as predict customer revenue.
We first predict customer’s tendency to make a purchase in the store. We first want to know what leads to a customer completing a purchase on the store before we try to estimate how much he purchases. 

For this we try to maximize the recall score of the model so that we capture all possible purchases. Next, we use this prediction as an indicator for predicting the revenue for these customers. We filter only the customers who have made a purchase from the first prediction and predict revenue for those customers only. This helps reduce the final error (rmse) and give out a better prediction.

Finally our goal for this prediction is to find important features, which can aid a manager in
finding potential customers who are likely to make a purchase. These customers can be
targeted and also, Store planning can be accordingly done for better customer experience.



## Data Mining

### Data Exploration

We are provided with 2 datasets, train and test with following sizes.
**train.csv - 24 GB**
**test.csv - 7 GB**
The prediction variable is the logarithmic revenue of the store visit, which is required at a customer level. Each row in the data represents a visit by a customer, and there are various attributes captures by google analytics for one visit.

The data fields in the given files with their data understanding are as below:
● **fullVisitorId**- Unique Customer ID
● **channelGrouping** - How User visited the store
● **date** - The date on which the user visited the Store.
● **device** - Details on how user accessed the website
● **geoNetwork** - User Geographic details demographics data
● **sessionId** - Unique ID for the session of the user
● **socialEngagementType** - "Socially Engaged" / "Not Socially Engaged".
● **totals** - These contains various session attributes
● **trafficSource** - Traffic Source of the section
● **visitId** - An identifier for this visit
● **visitNumber** - The session number for this user. If this is the first visit, then this is set to 1.
● **visitStartTime** - The timestamp for the visit

The train data ranges from 1st August 2016 to 30th April 2018. And the test data is for 5.5 months ranging from 1st May 2019 to 15th October 2019.

Many data fields are also in Json format which first needs to be unpacked and flattened into columns, before analyzing and using the data.



### Data Cleaning

The imported data had following files in Json format. We use the following function to flatten these files and convert them into required columns.

```python
JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']
for column in JSON_COLUMNS:
5
column_as_df = json_normalize(df1[column])
column_as_df.columns = [f"{column}.{subcolumn}" for subcolumn in
column_as_df.columns]
df1 = df1.drop(column, axis=1).merge(column_as_df, right_index=True,
left_index=True, how = 'left')
```

These expanded fields give multiple columns which have no values in them and are zero. We neglect these columns and go ahead with columns which have further values in them for feature selection.